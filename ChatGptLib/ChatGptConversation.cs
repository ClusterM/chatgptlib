using System.Runtime.CompilerServices;
using System.Text.Json;
using System.Threading;
using wtf.cluster.ChatGptLib.Types;
using wtf.cluster.ChatGptLib.Types.Tools;
using static wtf.cluster.ChatGptLib.Types.ChatMessage;

namespace wtf.cluster.ChatGptLib
{
    /// <summary>
    /// ChatGPT conversation helper.
    /// It tracks chat history and performs automatic function calling.
    /// </summary>
    public class ChatGptConversation
    {
        /// <summary>
        /// ID of the model to use. See the model endpoint compatibility table for details on which models work with the Chat API.
        /// </summary>
        public string? Model { get; set; }

        /// <summary>
        /// What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.
        /// Default is 1.
        /// </summary>
        public double? Temperature { get; set; }

        /// <summary>
        /// An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.
        /// Default is 0.5.
        /// </summary>
        public double? TopP { get; set; }

        /// <summary>
        /// The maximum number of tokens to generate in the chat completion.
        /// </summary>
        public int? MaxTokens { get; set; }

        /// <summary>
        /// Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.
        /// Default is 0.
        /// </summary>
        public double? PresencePenalty { get; set; }

        /// <summary>
        /// Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.
        /// Default is 0.
        /// </summary>
        public double? FrequencyPenalty { get; set; }

        /// <summary>
        /// Modify the likelihood of specified tokens appearing in the completion. Accepts a json object that maps tokens(specified by their token ID in the tokenizer) to an associated bias value from -100 to 100. 
        /// Mathematically, the bias is added to the logits generated by the model prior to sampling.The exact effect will vary per model, but values between -1 and 1 should decrease or increase likelihood of selection.
        /// Values like -100 or 100 should result in a ban or exclusive selection of the relevant token.
        /// </summary>
        public Dictionary<string, double>? LogitBias { get; set; }

        /// <summary>
        /// A unique identifier representing your end-user, which can help OpenAI to monitor and detect abuse.
        /// </summary>
        public string? User { get; set; }

        /// <summary>
        /// If specified, our system will make a best effort to sample deterministically, such that repeated requests with the same seed and parameters should return the same result.
        /// Determinism is not guaranteed, and you should refer to the system_fingerprint response parameter to monitor changes in the backend.
        /// </summary>
        public int? Seed { get; set; }

        /// <summary>
        /// System message. Descript here how AI should answer.
        /// </summary>
        public string? SystemMessage { get; set; }

        /// <summary>
        /// Maximum number of user messages. Chat history will be trimmed to this value.
        /// E.g. defines how much conversation context keeps in mind.
        /// </summary>
        public int? WindowSize { get; set; }

        /// <summary>
        /// Messages history.
        /// </summary>
        public List<ChatMessage> Messages { get; set; } = new();

        /// <summary>
        /// Functions list.
        /// </summary>
        public Dictionary<string, ChatFunctionMethod> Functions { get; set; } = new();

        private readonly ChatGptClient gpt;


        /// <summary>
        /// ChatGptConversation constructor.
        /// </summary>
        /// <param name="apiKey">OpenAI API key.</param>
        /// <param name="model">Model name.</param>
        public ChatGptConversation(string apiKey, string model = "")
        {
            Model = model;
            gpt = new ChatGptClient(apiKey);
        }

        /// <summary>
        /// Add text message from user.
        /// </summary>
        /// <param name="message">Message text.</param>
        public void AddMessage(string message)
            => Messages.Add(new ChatMessage(role: ChatMessage.ChatMessageRole.User, content: message));

        /// <summary>
        /// Add ChatMessage to the history.
        /// </summary>
        /// <param name="message">Message text.</param>
        public void AddMessage(ChatMessage message)
            => Messages.Add(message);

        /// <summary>
        /// Get next assistant answer.
        /// </summary>
        /// <param name="o">Optional object to pass to a functions.</param>
        /// <param name="cancellationToken">Cancellation token.</param>
        /// <returns>Assistent answer as string.</returns>
        public async Task<string> GetAnswerAsync(object? o = null, CancellationToken cancellationToken = default)
        {
            ChatMessage? msg = null;
            RemoveOldMessages();

            do
            {
                var newMessages = new List<ChatMessage>();
                // Add system message
                var tmpMessages = new List<ChatMessage>(Messages);
                if (!String.IsNullOrEmpty(SystemMessage))
                    tmpMessages.Insert(0, new ChatMessage(ChatMessageRole.System, SystemMessage));
                // Build request.
                var request = new ChatRequest()
                {
                    Model = Model,
                    Temperature = Temperature,
                    TopP = TopP,
                    MaxTokens = MaxTokens,
                    PresencePenalty = PresencePenalty,
                    FrequencyPenalty = FrequencyPenalty,
                    LogitBias = LogitBias,
                    User = User,
                    Seed = Seed,
                    Messages = tmpMessages,
                    N = 1,
                    Tools = Functions.Any() ? new List<IChatTool>(Functions.Select(kv => new ChatToolFunction(new ChatFunction()
                    {
                        Name = kv.Key,
                        Description = kv.Value.Description,
                        Parameters = kv.Value.Parameters
                    }))) : null
                };

                // Make request
                var completionResult = await gpt.RequestAsync(request, cancellationToken).ConfigureAwait(false);
                msg = completionResult.Choices.First().Message!;
                // Add message to the history
                newMessages.Add(msg);

                // Proceed tools/functions if any
                if (msg.ToolCalls?.Any() == true)
                {
                    foreach (var tool in msg.ToolCalls)
                    {
                        switch (tool.Type)
                        {
                            case IChatTool.ToolType.Function:
                                // It's a function call
                                if (!Functions.TryGetValue(tool.Function!.Name!, out ChatFunctionMethod? function))
                                    throw new NotImplementedException($"Unknown function: {tool.Function!.Name}");
                                // Call the function
                                var argsDoc = JsonDocument.Parse(tool.Function!.Arguments!);
                                var functionResult = await function!.Function(argsDoc.RootElement, o, cancellationToken).ConfigureAwait(false);
                                // Need to add function result to the chat history
                                var functionResultMessage = new ChatMessage(ChatMessageRole.Tool, functionResult, tool.Function?.Name)
                                {
                                    ToolCallId = tool.Id
                                };
                                newMessages.Add(functionResultMessage);
                                break;
                            default:
                                throw new NotImplementedException($"Unknown tool type: {tool.Type}");
                        }
                    }
                }
                Messages.AddRange(newMessages);
                // Until there is no tool calls
            } while (msg?.ToolCalls?.Any() == true);
            
            return $"{msg?.Content}";
        }

        /// <summary>
        /// Get next assistant answer as a async text stream.
        /// </summary>
        /// <param name="o">Optional object to pass to a functions.</param>
        /// <param name="cancellationToken">Cancellation token.</param>
        /// <returns>Assistent answer as string (parts).</returns>
        public async IAsyncEnumerable<string> GetAnswerStreamAsync(object? o = null, [EnumeratorCancellation] CancellationToken cancellationToken = default)
        {
            ChatMessage? msg = null;

            RemoveOldMessages();

            do
            {
                var newMessages = new List<ChatMessage>();
                // Add system message
                var tmpMessages = new List<ChatMessage>(Messages);
                if (!String.IsNullOrEmpty(SystemMessage))
                    tmpMessages.Insert(0, new ChatMessage(ChatMessageRole.System, SystemMessage));
                // Build request.
                var request = new ChatRequest()
                {
                    Model = Model,
                    Temperature = Temperature,
                    TopP = TopP,
                    MaxTokens = MaxTokens,
                    PresencePenalty = PresencePenalty,
                    FrequencyPenalty = FrequencyPenalty,
                    LogitBias = LogitBias,
                    User = User,
                    Seed = Seed,
                    Messages = tmpMessages,
                    N = 1,
                    Tools = new List<IChatTool>(Functions.Select(kv => new ChatToolFunction(new ChatFunction()
                    {
                        Name = kv.Key,
                        Description = kv.Value.Description,
                        Parameters = kv.Value.Parameters
                    })))
                };

                // Make request
                var completionResult = new ChatResponse();
                var completionResultStream = gpt.RequestStreamAsync(request, cancellationToken).ConfigureAwait(false);
                await foreach (var p in completionResultStream)
                {
                    completionResult = completionResult! + p;
                    if (completionResult?.Choices?.First()?.Message?.ToolCalls != null)
                        continue;
                    var r = p.Choices?.FirstOrDefault()?.Delta?.Content?.ToString();
                    if (!String.IsNullOrEmpty(r))
                        yield return r;
                }
                msg = completionResult!.Choices.First().Message!;
                // Add message to the history
                newMessages.Add(msg);

                // Proceed tools/functions if any
                if (msg.ToolCalls?.Any() == true)
                {
                    foreach (var tool in msg.ToolCalls)
                    {
                        switch (tool.Type)
                        {
                            case IChatTool.ToolType.Function:
                                // It's a function call
                                if (!Functions.TryGetValue(tool.Function!.Name!, out ChatFunctionMethod? function))
                                    throw new NotImplementedException($"Unknown function: {tool.Function!.Name}");
                                // Call the function
                                var argsDoc = JsonDocument.Parse(tool.Function!.Arguments!);
                                var functionResult = await function!.Function(argsDoc.RootElement, o, cancellationToken).ConfigureAwait(false);
                                // Need to add function result to the chat history
                                var functionResultMessage = new ChatMessage(ChatMessageRole.Tool, functionResult, tool.Function?.Name)
                                {
                                    ToolCallId = tool.Id
                                };
                                newMessages.Add(functionResultMessage);
                                break;
                            default:
                                throw new NotImplementedException($"Unknown tool type: {tool.Type}");
                        }
                    }
                }
                Messages.AddRange(newMessages);
                // Until there is no tool calls
            } while (msg?.ToolCalls?.Any() == true);
            yield return String.Empty;
        }

        /// <summary>
        /// Save message history to the file.
        /// </summary>
        /// <param name="filename">Filename.</param>
        /// <param name="cancellationToken">Cancellation token.</param>
        public async Task SaveMessagesAsync(string filename, CancellationToken cancellationToken = default) =>
            await File.WriteAllTextAsync(filename, JsonSerializer.Serialize(Messages, ChatGptClient.GetJsonOptions()), cancellationToken).ConfigureAwait(false);

        /// <summary>
        /// Load message history from the file.
        /// </summary>
        /// <param name="filename">Filename.</param>
        /// <param name="cancellationToken">Cancellation token.</param>
        public async Task LoadMessagesAsync(string filename, CancellationToken cancellationToken = default)
        {
            var r = JsonSerializer.Deserialize<List<ChatMessage>>(
                await File.ReadAllTextAsync(filename, cancellationToken).ConfigureAwait(false), ChatGptClient.GetJsonOptions()
            );
            if (r == null)
                throw new JsonException($"Can't parse {filename}");
            Messages = r;
        }

        private void RemoveOldMessages()
        {
            if (WindowSize == null) return;
            while (
                Messages.Where(m => m.Role == ChatMessageRole.User).Any() &&
                (
                    Messages.Where(m => m.Role == ChatMessageRole.User).Count() > WindowSize
                        || Messages.First().Role == ChatMessageRole.Assistant
                        || Messages.First().Role == ChatMessageRole.Tool
                )
            ) Messages.RemoveAt(0);
        }
    }
}
